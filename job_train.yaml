description: DPO


environment:
  image: lesong/nvidia-cuda:v5
  username: f2e15e898c154795b7a8c9a9d936095d
  registry: f2e15e898c154795b7a8c9a9d936095d.azurecr.io

  setup:
    - pip install -r environment_simpo.yaml
    # - pip install flash-attn --no-build-isolation
    
target:
  service: sing
  # name: msrresrchvc
  # name: msrresrchlab
  name: palisades03
  workspace_name: rag-workspace-eastus

data:
  local_dir: ./data/
  remote_dir: data/

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: ./


search:
  job_template:
    # you may use {random_string:s} to avoid job name collisions
    # {auto:3s} generates lr_0.00000_mom_0.5, .. etc
    # {auto:2s} generates lr_0.00000_mo_0.5, .. etc
    name: "{experiment_name:s}_{auto:3s}"
    identity: managed
    submit_args:
      env:
        _AZUREML_SINGULARITY_JOB_UAI: "/subscriptions/e033d461-1923-44a7-872b-78f1d35a86dd/resourcegroups/RAG-WUS/providers/Microsoft.ManagedIdentity/userAssignedIdentities/rag-workspace-eastus-mi"
    sku: 40G8
    command:
    - export PYTHONPATH=$$PWD; python config_generator.py task=train trainer_types={trainer_types} ref_models={ref_models}
  type: hyperdrive  # hyperparameter search type: hyperdrive, random, grid.  Default: hyperdrive
  sampling: grid  # how to explore the hyperparameter space: random, grid or bayesian. Default: bayesian
  max_trials: 28
  parallel_trials: 2  # number of trials to run in parallel. Default: equals to max_trials.
  params:
    - name: trainer_types
      values: ["SFTReg", "DPO-sigmoid", "alphaDPO", "SimPO", "IPO", "KTO", "rDPO"]
    - name: ref_models
      values: ["meta-llama/Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "mistralai/Mistral-7B-Instruct-v0.2", "google/gemma-2-9b-it"]